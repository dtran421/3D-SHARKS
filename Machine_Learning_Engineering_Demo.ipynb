{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtran421/3D-SHARKS/blob/main/Machine_Learning_Engineering_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Engineering Demo\n",
        "\n",
        "In this notebook, we will walk through a simple machine learning project and see how it can be applied to software. This project focuses on identifying whether an email is spam or not (\"ham\" or \"spam\")."
      ],
      "metadata": {
        "id": "ahDQxeGhArhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19PHdwE808S3"
      },
      "outputs": [],
      "source": [
        "#@title Import statements for ML-related modules {display-mode: \"form\"}\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "In this section, we perform preprocessing on our data and then train the model on this data. Your job here is to run each code cell and understand what is going on."
      ],
      "metadata": {
        "id": "qSSuV0HKK56u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import the Enron Dataset to train the machine learning model {display-mode: \"form\"}\n",
        "DATA_URL = 'https://raw.githubusercontent.com/dtran421/machine-learning-engineering-demo/main/enron_data.csv'\n",
        "df = pd.read_csv(DATA_URL, index_col=0)"
      ],
      "metadata": {
        "id": "KjOE3Y9F24Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize constant variables {display-mode: \"form\"}\n",
        "# these counts will be used later on for shuffling and subsetting the data\n",
        "numTotal    = len(df)\n",
        "numTrain    = int(.8*numTotal)\n",
        "numTest     = numTotal-numTrain\n",
        "\n",
        "# maximum amount of features that we want our feature vectors to contain\n",
        "numFeatures = 3000"
      ],
      "metadata": {
        "id": "-k4pM5hW8T7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize lists for labels and docs (email messages) {display-mode: \"form\"}\n",
        "#@markdown Labels: 0 = ham (*legitimate*), 1 = spam\n",
        "labels = df['Label']   # list of labels for each email\n",
        "docs   = df['Body']    # list of emails"
      ],
      "metadata": {
        "id": "waxDD0x22Tl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize preprocessor and vectorizor {display-mode: \"form\"}\n",
        "\n",
        "# this function will be called on each message to preprocess it\n",
        "def preprocess(doc):\n",
        "    # replace all currency signs and some url patterns with special\n",
        "    # tokens as these are useful features.\n",
        "    doc = re.sub('[Â£$]', ' __currency__ ', doc)\n",
        "    doc = re.sub('\\://', ' __url__ ', doc)\n",
        "    doc = doc.lower()\n",
        "    return doc\n",
        "\n",
        "\n",
        "# vectorizer is responsible for converting bodies of text into feature vectors\n",
        "# these vectors are much easier for a machine learning model to deal with\n",
        "vectorizer = CountVectorizer(max_features=numFeatures, preprocessor=preprocess)"
      ],
      "metadata": {
        "id": "J5P6x57m6nwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Vectorize docs (email messages) {display-mode: \"form\"}\n",
        "# now, we actually perform the conversion from text to feature vectors\n",
        "X = vectorizer.fit_transform(docs)"
      ],
      "metadata": {
        "id": "XP2OQIVt_Stl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create data structures to hold data and labels {display-mode: \"form\"}\n",
        "\n",
        "# dense numpy arrays will be easier to work with\n",
        "X = X.toarray()\n",
        "m,n = X.shape\n",
        "y = labels.array\n",
        "\n",
        "# add a column of ones (bias of the hypothesis function)\n",
        "# this is kind of like the y-intercept\n",
        "X = np.column_stack([np.ones(m), X])"
      ],
      "metadata": {
        "id": "hDZQQGzP_01G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Shuffle datapoints {display-mode: \"form\"}\n",
        "# randomize the indices of our data\n",
        "idx = np.arange(numTotal)\n",
        "np.random.shuffle(idx)"
      ],
      "metadata": {
        "id": "JIJE_V4fGhT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split dataset into training and testing sets (email messages) {display-mode: \"form\"}\n",
        "\n",
        "# apply the randomized indices to our model input\n",
        "X = X[idx,:]\n",
        "y = y[idx]\n",
        "\n",
        "# split into training and testing sets\n",
        "# we have hard coded the split between training and testing to be 80:20\n",
        "train = np.arange(numTrain)\n",
        "test  = numTrain + np.arange(numTest)\n",
        "\n",
        "X_train = X[train,:]\n",
        "y_train = y[train]\n",
        "\n",
        "X_test  = X[test,:]\n",
        "y_test  = y[test]"
      ],
      "metadata": {
        "id": "nO3cCOJU_Vh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Random Forest Regressor\n",
        "\n",
        "In this first model, we will walk you through the Random Forest Regressor, a model that averages across many classifying decision trees to come up with a final classification."
      ],
      "metadata": {
        "id": "H2hlSUS9txPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model and then fit it to our data\n",
        "model = RandomForestRegressor(max_features=.3, n_estimators=25)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# feel free to change or add parameters and see how it affects the \n",
        "# training time (very bottom left while running a cell) and model accurracy\n",
        "# as a warning, increasing values too much can greatly increase execution time\n",
        "# docs: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa-BGNfinwgf",
        "outputId": "5967f53c-3bd2-48ed-949c-c4fd814e3af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features=0.3, n_estimators=25)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a prediction for our test data\n",
        "pred_enron = model.predict(X_test)\n",
        "\n",
        "# now we check to see how well our model works\n",
        "res = np.sum(np.abs(pred_enron - y_test))\n",
        "acc = 100 - (res / numTest * 100)\n",
        "print(f'Model Accuracy: {acc}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4loUlgQQodB8",
        "outputId": "27cd0798-eb2d-4588-c688-262dfc805962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 91.844%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: Logistic Regression\n",
        "\n",
        "That accuracy is okay, but maybe the Random Forest Regressor isn't the best choice. Let's try a Logistic Regression, which is a simple type of linear model that can be used to predict the probability of a binary event occurring. This time, it's your turn to implement the training and testing. You can reference our code above when implementing."
      ],
      "metadata": {
        "id": "0_s6nEg_u5Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create a new model \"model\" using \"LogisticRegression\" \n",
        "# for params, we recommend using max_iter=500 and solver='liblinear'\n",
        "# feel free to play around with these params to try to get better accuracy\n",
        "\n",
        "\n",
        "# TODO: fit it to our data \"X_train\" and \"y_train\"\n",
        "\n",
        "\n",
        "# docs: https://scikit-learn.org/stable/modules/linear_model.html?highlight=logistic+regress#logistic-regression"
      ],
      "metadata": {
        "id": "3oTLOjYVFOH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d09b3e-c0f5-433f-ee63-8166ff3e8810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=500, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create a prediction \"pred_enron\" for our test data \"X_test\"\n",
        "\n",
        "\n",
        "# now we check to see how well our model works\n",
        "res = np.sum(np.abs(pred_enron - y_test))\n",
        "acc = 100 - (res / numTest * 100)\n",
        "print(f'Model Accuracy: {acc}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Itp1OVGySu",
        "outputId": "bca7d64f-a5ed-49f9-d4a0-fc750917e7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try it yourself\n",
        "\n",
        "In this section, we have left out some code necessary for testing out the model on a new dataset (Ling Dataset) that it has never seen before. It is up to you to fill in a few lines and create new predictions using the model we trained above."
      ],
      "metadata": {
        "id": "lpnduflQBu34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: read in Ling Dataset CSV from https://raw.githubusercontent.com/dtran421/machine-learning-engineering-demo/main/ling_data.csv\n"
      ],
      "metadata": {
        "id": "bMEWNzjWG7hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here, we will perform same preprocessing steps that we did previously\n",
        "numTotal    = len(df)\n",
        "numTrain    = int(.8*numTotal)\n",
        "numTest     = numTotal-numTrain\n",
        "\n",
        "labels = df['Label']   # list of labels for each email\n",
        "docs   = df['Body']    # list of emails\n",
        "\n",
        "# convert the email content to feature vectors\n",
        "X = vectorizer.fit_transform(docs)\n",
        "\n",
        "# read into arrays\n",
        "X = X.toarray()\n",
        "m,n = X.shape\n",
        "y = labels.array\n",
        "\n",
        "# add column of ones\n",
        "X = np.column_stack([np.ones(m), X])"
      ],
      "metadata": {
        "id": "nDHCLOeKIzfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create a prediction \"pred_ling\" using the pre-trained model\n",
        "# the parameter should be \"X\" this time instead of \"X_test\"\n"
      ],
      "metadata": {
        "id": "va6GPsiyI2Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare predicted y to y_tests\n",
        "res = np.sum(np.abs(pred_ling - y))\n",
        "acc = 100 - (res / numTest * 100)\n",
        "print(f'Model Accuracy {acc}%')"
      ],
      "metadata": {
        "id": "l8ZvwYycJvOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521a9902-cf57-4e5a-9ddc-b94081c57bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Now you've trained and tested a model that can accurately predict whether an email is \"ham\" or \"spam\". Why does this matter and how can it be applied?\n",
        "\n",
        "Let's consider a service like Gmail. As everyone knows, this is an email service provided by Google that has many additional features like a spam inbox that is separate from the main inbox. If users had to manually move spam email to this inbox, it would be a passive pain for them. Instead, Google has a similar machine learning algorithm to the one we created above (except theirs is probably a bit better and more complicated). The algorithm creates a \"prediction\" for every email received by the user and assigns the email to the corresponding inbox. This is exactly what Machine Learning Engineering is!"
      ],
      "metadata": {
        "id": "90IXxJN1MEwj"
      }
    }
  ]
}